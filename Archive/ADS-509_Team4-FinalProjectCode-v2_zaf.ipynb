{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17b7fc61",
   "metadata": {},
   "source": [
    "# Appendix\n",
    "## ADS 509: Final Project Code\n",
    "## Team 4\n",
    "### Zachariah Freitas and Brianne Bell\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0877ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install arxiv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cb3f657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import nltk\n",
    "from collections import Counter, defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from tqdm import tqdm\n",
    "import sqlite3\n",
    "\n",
    "# from https://github.com/soumik12345/multi-label-text-classification/blob/master/arxiv_scrape.ipynb\n",
    "import arxiv\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c0ee16de",
   "metadata": {},
   "source": [
    "The guide we are using used these keywords for multiclass classification:\n",
    "query_keywords = [\n",
    "    \"\\\"image segmentation\\\"\",\n",
    "    \"\\\"self-supervised learning\\\"\",\n",
    "    \"\\\"representation learning\\\"\",\n",
    "    \"\\\"image generation\\\"\",\n",
    "    \"\\\"object detection\\\"\",\n",
    "    \"\\\"transfer learning\\\"\",\n",
    "    \"\\\"transformers\\\"\",\n",
    "    \"\\\"adversarial training\",\n",
    "    \"\\\"generative adversarial networks\\\"\",\n",
    "    \"\\\"model compressions\\\"\",\n",
    "    \"\\\"image segmentation\\\"\",\n",
    "    \"\\\"few-shot learning\\\"\",\n",
    "    \"\\\"natural language\\\"\",\n",
    "    \"\\\"graph\\\"\",\n",
    "    \"\\\"colorization\\\"\",\n",
    "    \"\\\"depth estimation\\\"\",\n",
    "    \"\\\"point cloud\\\"\",\n",
    "    \"\\\"structured data\\\"\",\n",
    "    \"\\\"optical flow\\\"\",\n",
    "    \"\\\"reinforcement learning\\\"\",\n",
    "    \"\\\"super resolution\\\"\",\n",
    "    \"\\\"attention\\\"\",\n",
    "    \"\\\"tabular\\\"\",\n",
    "    \"\\\"unsupervised learning\\\"\",\n",
    "    \"\\\"semi-supervised learning\\\"\",\n",
    "    \"\\\"explainable\\\"\",\n",
    "    \"\\\"radiance field\\\"\",\n",
    "    \"\\\"decision tree\\\"\",\n",
    "    \"\\\"time series\\\"\",\n",
    "    \"\\\"molecule\\\"\",\n",
    "    \"\\\"physics\\\"\",\n",
    "    \"\\\"graphics\\\"\",\n",
    "    \"\\\"ray tracing\\\"\",\n",
    "    \"\\\"optical flow\\\"\",\n",
    "    \"\\\"photogrametry\\\"\",\n",
    "]\n",
    "Thinking this is kind of an extensive list for a 2 week project so taking only some or adding some"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d787a25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doing similar set up with setting up keywords to focus on\n",
    "query_keywords = [\n",
    "    \"\\\"representation learning\\\"\",\n",
    "    \"\\\"image generation\\\"\",\n",
    "    \"\\\"object detection\\\"\",\n",
    "    \"\\\"transformers\\\"\",\n",
    "    \"\\\"image segmentation\\\"\",\n",
    "    \"\\\"natural language\\\"\",\n",
    "    \"\\\"graph\\\"\",\n",
    "    \"\\\"colorization\\\"\",\n",
    "    \"\\\"depth estimation\\\"\",\n",
    "    \"\\\"point cloud\\\"\",\n",
    "    \"\\\"structured data\\\"\",\n",
    "    \"\\\"reinforcement learning\\\"\",\n",
    "    \"\\\"attention\\\"\",\n",
    "    \"\\\"tabular\\\"\",\n",
    "    \"\\\"unsupervised learning\\\"\",\n",
    "    \"\\\"semi-supervised learning\\\"\",\n",
    "    \"\\\"explainable\\\"\",\n",
    "    \"\\\"time series\\\"\",\n",
    "    \"\\\"molecule\\\"\",\n",
    "    \"\\\"physics\\\"\",\n",
    "    \"\\\"graphics\\\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6aeeed92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/soumik12345/multi-label-text-classification/blob/master/arxiv_scrape.ipynb\n",
    "client = arxiv.Client(num_retries=20, page_size=500)\n",
    "\n",
    "def query_with_keywords(query):\n",
    "    search = arxiv.Search(\n",
    "        query=query,\n",
    "        max_results=20000,\n",
    "        sort_by=arxiv.SortCriterion.LastUpdatedDate\n",
    "    )\n",
    "    terms = []\n",
    "    titles = []\n",
    "    abstracts = []\n",
    "    for res in tqdm(client.results(search), desc=query):\n",
    "        if res.primary_category in [\"cs.CV\", \"stat.ML\", \"cs.LG\"]:\n",
    "            terms.append(res.categories)\n",
    "            titles.append(res.title)\n",
    "            abstracts.append(res.summary)\n",
    "    return terms, titles, abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8c89c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up save file\n",
    "# if not os.path.isdir(\"arxiv_data\") : \n",
    "#     os.mkdir(\"arxiv_data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "383f5753",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"representation learning\": 6118it [01:41, 60.09it/s]\n",
      "\"image generation\": 1978it [00:30, 64.01it/s]\n",
      "\"object detection\": 6536it [02:01, 53.69it/s]\n",
      "\"transformers\": 20000it [06:55, 48.10it/s]\n",
      "\"image segmentation\": 2890it [00:43, 66.93it/s]\n",
      "\"natural language\": 13021it [03:36, 60.18it/s]\n",
      "\"graph\": 20000it [05:39, 58.89it/s]\n",
      "\"colorization\": 20000it [05:37, 59.20it/s]\n",
      "\"depth estimation\": 1218it [00:20, 60.71it/s]\n",
      "\"point cloud\": 4308it [01:30, 47.41it/s]\n",
      "\"structured data\": 1915it [00:35, 54.30it/s]\n",
      "\"reinforcement learning\": 16211it [04:36, 58.58it/s]\n",
      "\"attention\": 20000it [05:48, 57.44it/s]\n",
      "\"tabular\": 1382it [00:21, 63.47it/s]\n",
      "\"unsupervised learning\": 2763it [00:41, 66.14it/s]\n",
      "\"semi-supervised learning\": 0it [00:03, ?it/s]\n",
      "\"explainable\": 20000it [06:17, 52.97it/s]\n",
      "\"time series\": 15302it [04:17, 59.39it/s]\n",
      "\"molecule\": 20000it [05:29, 60.67it/s]\n",
      "\"physics\": 20000it [08:39, 38.50it/s]\n",
      "\"graphics\": 15861it [04:34, 57.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:10:04.621341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# setting up for pull\n",
    "all_titles = []\n",
    "all_summaries = []\n",
    "all_terms = []\n",
    "\n",
    "# timing:\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "# pulling\n",
    "for query in query_keywords:\n",
    "    terms, titles, abstracts = query_with_keywords(query)\n",
    "    all_titles.extend(titles)\n",
    "    all_summaries.extend(abstracts)\n",
    "    all_terms.extend(terms)\n",
    "    \n",
    "# seeing how long ^that took:    \n",
    "end_time = datetime.datetime.now()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3afdf1f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titles</th>\n",
       "      <th>abstracts</th>\n",
       "      <th>terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reinforcement Learning from Multiple Sensors v...</td>\n",
       "      <td>In many scenarios, observations from more than...</td>\n",
       "      <td>[cs.LG]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Interventional Causal Representation Learning</td>\n",
       "      <td>Causal representation learning seeks to extrac...</td>\n",
       "      <td>[stat.ML, cs.LG]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Self-Supervised Node Representation Learning v...</td>\n",
       "      <td>Self-supervised node representation learning a...</td>\n",
       "      <td>[cs.LG]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Out-of-Distribution Representation Learning fo...</td>\n",
       "      <td>Time series classification is an important pro...</td>\n",
       "      <td>[cs.LG, cs.AI]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trading Information between Latents in Hierarc...</td>\n",
       "      <td>Variational Autoencoders (VAEs) were originall...</td>\n",
       "      <td>[stat.ML, cs.CV, cs.IT, cs.LG, math.IT]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              titles  \\\n",
       "0  Reinforcement Learning from Multiple Sensors v...   \n",
       "1      Interventional Causal Representation Learning   \n",
       "2  Self-Supervised Node Representation Learning v...   \n",
       "3  Out-of-Distribution Representation Learning fo...   \n",
       "4  Trading Information between Latents in Hierarc...   \n",
       "\n",
       "                                           abstracts  \\\n",
       "0  In many scenarios, observations from more than...   \n",
       "1  Causal representation learning seeks to extrac...   \n",
       "2  Self-supervised node representation learning a...   \n",
       "3  Time series classification is an important pro...   \n",
       "4  Variational Autoencoders (VAEs) were originall...   \n",
       "\n",
       "                                     terms  \n",
       "0                                  [cs.LG]  \n",
       "1                         [stat.ML, cs.LG]  \n",
       "2                                  [cs.LG]  \n",
       "3                           [cs.LG, cs.AI]  \n",
       "4  [stat.ML, cs.CV, cs.IT, cs.LG, math.IT]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.DataFrame({\n",
    "    'titles': all_titles,\n",
    "    'abstracts': all_summaries,\n",
    "    'terms': all_terms\n",
    "})\n",
    "\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2c59ca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64573, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.shape #(64573, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "470c61d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving to csv file because pulling data takes a long while\n",
    "\n",
    "    # well I didn't get it to the file folder but it did write.\n",
    "\n",
    "\n",
    "# This is how you save a pandas dataframe and all the details associated with it.  You do so as a binary file.\n",
    "raw_data.to_pickle('G:\\\\My Drive\\\\ADS-509_Final_Team_Project\\\\arxiv_data_2023_02_13.pkl')\n",
    "\n",
    "# Nextime you want to use it.  All you have to do is read it as a pickle file. The file you will read is a pandas dataframe.\n",
    "# raw_data = pd.read_pickle('G:\\\\My Drive\\\\ADS-509_Final_Team_Project\\\\arxiv_data_2023_02_13.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159bda0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "4b33cfd37f5195bd7836c1451c6eaacc84fbbad3c54541ec8bad2790bfb3f777"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
